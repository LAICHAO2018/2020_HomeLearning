====> 第一节
====>>> Requests库 自动爬取HTML页面，自动网络请求提交
====>>> robots.txt 网络爬虫排除标准
====>>> Beautiful Soup 解析HTML页面
====>>> Re库，正则表达式详解，提取页面关键信息
====>>> 第三方库 Scrapy 网络爬虫库



  
